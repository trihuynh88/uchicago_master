@inproceedings{Brosz2007,
address = {New York, New York, USA},
author = {Brosz, John and Samavati, Faramarz F. and Carpendale, M. Sheelagh T. and Sousa, Mario Costa},
booktitle = {Proceedings of the 5th international symposium on Non-photorealistic animation and rendering - NPAR '07},
doi = {10.1145/1274871.1274876},
isbn = {9781595936240},
keywords = {non-photorealistic rendering,non-standard camera,nonlinear ray casting,parametric modeling,projection},
mendeley-tags = {non-standard camera},
month = {aug},
pages = {33},
publisher = {ACM Press},
title = {{Single camera flexible projection}},
url = {http://dl.acm.org/citation.cfm?id=1274871.1274876},
year = {2007}
}
@article{Degener2008,
abstract = {In this work we develop a new alternative to conventional maps for visualization of relatively short paths as they are frequently encountered in hotels, resorts or museums. Our approach is based on a warped rendering of a 3D model of the environment such that the visualized path appears to be straight even though it may contain several junctions. This has the advantage that the beholder of the image gains a realistic impression of the surroundings along the way which makes it easy to retrace the route in practice. We give an intuitive method for generation of such images and present results from user studies undertaken to evaluate the benefit of the warped images for orientation in unknown environments.},
author = {Degener, Patrick and Schnabel, Ruwen and Schwartz, Christopher and Klein, Reinhard},
doi = {10.1109/TVCG.2008.124},
file = {:C$\backslash$:/Users/TRI HUYNH/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Degener et al. - 2008 - Effective visualization of short routes.pdf:pdf},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
number = {6},
pages = {1452--8},
pmid = {18988996},
title = {{Effective visualization of short routes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18988996},
volume = {14},
year = {2008}
}
@article{Max,
abstract = {This article is intended as an update of the major survey by Max [40] on optical models for direct volume rendering. It provides a brief overview of the subject scope covered by [40], and brings recent develop- ments, such as new shadow algorithms and refraction rendering, into the perspective. In particular, we examine three fundamentals aspects of direct volume rendering, namely the volume rendering integral, local illumination models and global illumination models, in a wavelength-independent manner. We re- view the developments on spectral volume rendering, in which visible light are considered as a form of electromagnetic radiation, optical models are implemented in conjunction with representations of spectral power distribution. This survey can provide a basis for, and encourage, new efforts for developing and using complex illumination models to achieve better realism and perception through optical correctness.},
author = {Max, Nelson and Chen, Min},
file = {:F$\backslash$:/UChicago/Study/SciVis/papers/18.pdf:pdf},
journal = {Scientific Visualization},
keywords = {Illumination Model,Volume Rendering},
pages = {259--274},
title = {{Local and Global Illumination in the Volume Rendering Integral}}
}
@article{Knoll2009,
abstract = {Direct volume rendering and isosurfacing are ubiquitous rendering techniques in scientific visualization, commonly employed in imaging 3D data from simulation and scan sources. Conventionally, these methods have been treated as separate modalities, necessitating different sampling strategies and rendering algorithms. In reality, an isosurface is a special case of a transfer function, namely a Dirac impulse at a given isovalue. However, artifact-free rendering of discrete isosurfaces in a volume rendering framework is an elusive goal, requiring either infinite sampling or smoothing of the transfer function. While preintegration approaches solve the most obvious deficiencies in handling sharp transfer functions, artifacts can still result, limiting classification. In this paper, we introduce a method for rendering such features by explicitly solving for isovalues within the volume rendering integral. In addition, we present a sampling strategy inspired by ray differentials that automatically matches the frequency of the image plane, resulting in fewer artifacts near the eye and better overall performance. These techniques exhibit clear advantages over standard uniform ray casting with and without preintegration, and allow for high-quality interactive volume rendering with sharp C0 transfer functions.},
author = {Knoll, Aaron and Hijazi, Younis and Westerteiger, Rolf and Schott, Mathias and Hansen, Charles and Hagen, Hans},
doi = {10.1109/TVCG.2009.204},
file = {:F$\backslash$:/UChicago/Study/SciVis/papers/05290775.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {direct volume rendering,isosurface,preintegration,ray casting,ray differentials,sampling,transfer function,view dependent},
number = {6},
pages = {1571--1578},
pmid = {19834235},
title = {{Volume ray casting with peak finding and differential sampling}},
volume = {15},
year = {2009}
}
@misc{,
file = {:F$\backslash$:/UChicago/Study/SciVis/papers/maxTVCG95OpticalModelsForDirectVolumeRendering.pdf:pdf},
title = {{maxTVCG95OpticalModelsForDirectVolumeRendering.pdf}}
}
@article{Kotava2012,
abstract = {Peak finding provides more accurate classification for direct volume rendering by sampling directly at local maxima in a transfer function, allowing for better reproduction of high-frequency features. However, the 1D peak finding technique does not extend to higherdimensional classification. In this work, we develop a new method for peak finding with multidimensional transfer functions, which looks for peaks along the image of the ray. We use piecewise approximations to dynamically sample in transfer function space between world-space samples. As with unidimensional peak finding, this approach is useful for specifying transfer functions with greater precision, and for accurately rendering noisy volume data at lower sampling rates. Multidimensional peak finding produces comparable image quality with order-of-magnitude better performance, and can reproduce features omitted entirely by standard classification. With no precomputation or storage requirements, it is an attractive alternative to preintegration for multidimensional transfer functions.},
author = {Kotava, Natallia and Knoll, Aaron and Schott, Mathias and Garth, Christoph and Tricoche, Xavier and Kessler, Christoph and Cohen, Elaine and Hansen, Charles D. and Papka, Michael E. and Hagen, Hans},
doi = {10.1109/PacificVis.2012.6183587},
file = {:F$\backslash$:/UChicago/Study/SciVis/papers/multipeak{\_}pv.pdf:pdf},
isbn = {9781467308649},
issn = {2165-8765},
journal = {IEEE Pacific Visualization Symposium 2012, PacificVis 2012 - Proceedings},
keywords = {multidimensional transfer functions,peak finding,volume rendering},
pages = {161--168},
title = {{Volume rendering with multidimensional peak finding}},
volume = {vi},
year = {2012}
}
@article{Max1995,
abstract = {This tutorial survey paper reviews several different models for light interaction with volume densities of absorbing, glowing, reflecting, and/or scattering material. They are, in order of increasing realism, absorption only, emission only, emission and absorption combined, single scattering of external illumination without shadows, single scattering with shadows, and multiple scattering. For each model the paper provides the physical assumptions, describes the applications for which it is appropriate, derives the differential or integral equations for light transport, presents calculation methods for solving them, and shows output images for a data set representing a cloud. Special attention is given to calculation methods for the multiple scattering model},
author = {Max, Nelson},
doi = {10.1109/2945.468400},
file = {:F$\backslash$:/UChicago/Study/SciVis/papers/OpticalModelsLong.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Optical models,compositing,discrete ordinates method,emission,extinction,multiple scattering,participating media,volume rendering,volume shading,volume shadows},
number = {2},
pages = {99--108},
title = {{Optical Models for Direct Volume Rendering}},
volume = {1},
year = {1995}
}
@article{Engel2001,
abstract = {We introduce a novel texture-based volume rendering approach that achieves the image quality of the best post-shading approaches with far less slices. It is suitable for new flexible consumer graphics hardware and provides high image quality even for low-resolution volume data and non-linear transfer functions with high frequencies, without the performance overhead caused by rendering additional interpolated slices. This is especially useful for volumetric effects in computer games and professional scientific volume visualization, which heavily depend on memory bandwidth and rasterization power. We present an implementation of the algorithm on current programmable consumer graphics hardware using multi-textures with advanced texture fetch and pixel shading operations. We implemented direct volume rendering, volume shading, arbitrary number of isosurfaces, and mixed mode rendering. The performance does neither depend on the number of isosurfaces nor the definition of the transfer functions, and is therefore suited for interactive high-quality volume graphics.},
author = {Engel, Klaus and Kraus, Martin and Ertl, Thomas},
doi = {10.1145/383507.383515},
file = {:F$\backslash$:/UChicago/Study/SciVis/papers/paper{\_}GraphicsHardware2001.pdf:pdf},
isbn = {158113407X},
issn = {1560-2281},
journal = {Proceedings of the ACM SIGGRAPH/EUROGRAPHICS Workshop on Graphics Hardware},
keywords = {current pro,direct volume rendering,flexible graphics hardware,graphics hardware,implementation,multi textures,pc,rasterization,shading,volume,volume graphics,volume visualization,while technical details},
pages = {9--16},
pmid = {23224164},
title = {{High-quality pre-integrated volume rendering using hardware-accelerated pixel shading}},
url = {http://portal.acm.org/citation.cfm?doid=383507.383515},
volume = {V},
year = {2001}
}
